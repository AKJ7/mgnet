{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train and test on CIFAR10 dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General imports and configuration"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create data loaders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision import transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[-7.5694e-02, -4.4422e-01,  3.0037e-01,  ..., -4.7766e-02,\n           -4.5992e-02,  1.2609e-01],\n          [-4.3092e-02, -7.5937e-01,  4.2197e-02,  ..., -1.2056e-01,\n           -5.7407e-01,  3.0940e-01],\n          [-1.9582e-01, -4.7558e-01,  1.3495e-01,  ..., -3.9650e-01,\n            2.9149e-01, -1.6527e-01],\n          ...,\n          [ 4.0915e-01, -5.5765e-01,  5.2827e-01,  ...,  8.7134e-01,\n           -7.1840e-01,  1.1114e-01],\n          [ 5.5658e-02,  6.3894e-01, -8.0076e-01,  ...,  8.0636e-01,\n            2.6405e-01,  5.5619e-02],\n          [-6.7639e-01, -4.9409e-01,  3.4016e-01,  ...,  3.3507e-01,\n            3.8831e-01,  6.9100e-02]],\n\n         [[ 1.4113e-01,  1.1670e-01, -4.9392e-01,  ...,  4.2130e-04,\n            1.6986e-01, -1.6310e-02],\n          [-2.8574e-01, -3.1625e-02, -4.9018e-01,  ...,  2.6022e-01,\n            4.6454e-01,  1.0635e-01],\n          [ 2.9555e-01,  8.1862e-02,  9.5443e-01,  ...,  8.8147e-02,\n           -7.7881e-02,  2.7128e-01],\n          ...,\n          [-3.1095e-01,  3.9667e-01,  7.8553e-01,  ..., -2.2698e-01,\n           -4.4915e-01,  2.9898e-01],\n          [ 4.6521e-01,  5.9603e-02,  4.7099e-01,  ..., -4.5476e-01,\n           -6.8838e-01,  4.0663e-03],\n          [-2.0539e-01, -3.2177e-01, -4.7958e-01,  ...,  3.6317e-01,\n            4.3461e-01,  1.1334e-01]],\n\n         [[ 1.3259e-01,  5.5592e-01, -8.0696e-01,  ...,  4.3583e-01,\n            3.5208e-01,  1.2818e-01],\n          [-2.5170e-02,  4.5204e-01,  1.2090e+00,  ..., -3.0423e-01,\n           -2.7833e-02,  3.6475e-01],\n          [ 6.5115e-01, -6.8535e-01,  4.3878e-01,  ..., -1.1449e+00,\n           -1.4234e+00,  2.7538e-01],\n          ...,\n          [ 7.3792e-03, -5.5954e-03,  8.5888e-01,  ...,  8.9648e-01,\n           -1.0505e+00,  2.0264e-01],\n          [-9.3734e-03, -4.6818e-01,  9.4270e-01,  ...,  6.7840e-01,\n            2.5862e-03,  4.1036e-01],\n          [-3.9041e-01, -4.5425e-01, -2.1589e-01,  ...,  3.1422e-01,\n            4.7273e-01, -6.9285e-02]]]], grad_fn=<ConvolutionBackward0>)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "inputs = torch.randn(1, 3, 32, 32)\n",
    "m = nn.Conv2d(3, 3, kernel_size=3, padding=1)\n",
    "res = F.conv_transpose2d(inputs, m.weight)\n",
    "\n",
    "\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}